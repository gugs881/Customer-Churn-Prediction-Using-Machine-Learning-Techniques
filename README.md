## ğŸ“„ Summary of Machine Learning Code

This notebook presents a **multiclass classification pipeline** designed to predict football match outcomes using various machine learning models. The workflow includes **data preprocessing**, **model training**, **evaluation**, and **comparison**.

---

### ğŸ” Key Steps

#### âœ… 1. Data Preparation
- Selected and cleaned features using `pandas`.
- Encoded categorical variables with `OneHotEncoder` and `OrdinalEncoder`.
- Split dataset into training and test sets using `train_test_split`.

#### âœ… 2. Models Implemented
- **Logistic Regression** â€“ baseline linear model.
- **Decision Tree** â€“ interpretable non-linear model.
- **Random Forest** â€“ ensemble method for generalization.
- **XGBoost** â€“ gradient boosting for high-performance classification.
- **CatBoost** â€“ optimized for categorical features.
- **SVM (LinearSVC)** â€“ effective on linearly separable data.
- **MLPClassifier** â€“ neural network (multilayer perceptron).

#### âœ… 3. Evaluation Metrics
- **Accuracy**
- **Classification Report** (precision, recall, F1-score)
- **Confusion Matrix**
- **ROC AUC** (One-vs-Rest strategy)

---

### ğŸ§ª Advanced Techniques
- Used **GridSearchCV** for hyperparameter optimization.
- Applied **K-Fold Cross-Validation** for robust evaluation.

---

### ğŸ Conclusion

This notebook delivers a complete machine learning workflow by comparing classic and ensemble classifiers with neural networks. Models like **XGBoost**, **CatBoost**, and **MLP** showed strong performance, assessed through comprehensive metrics such as ROC curves and confusion matrices.
